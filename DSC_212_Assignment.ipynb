{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dea6f1be-f5d7-4811-b7c8-9369010247ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./lib/python3.13/site-packages (3.5)\n",
      "Requirement already satisfied: numpy in ./lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: matplotlib in ./lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "____cell1 run_____\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "    --trusted-host pypi.org \\\n",
    "    --trusted-host files.pythonhosted.org \\\n",
    "    networkx numpy matplotlib\n",
    "print(\"____cell1 run_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e46e718b-baf8-40de-a5b8-fcdb3828ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______Cell2 ran_____\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "#to display the plot in the jupyter code block itself \n",
    "%matplotlib inline \n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 7)  #fixing configurations for the rest of the map\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"______Cell2 ran_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e73340ae-e536-4247-959b-c36a7d181918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Info:\n",
      "Nodes: 34\n",
      "Edges: 78\n",
      "________Cell3 run_______\n"
     ]
    }
   ],
   "source": [
    "G = nx.karate_club_graph()  #Loads Karate club graph\n",
    "\n",
    "print(\"Graph Info:\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")\n",
    "\n",
    "\n",
    "pos = nx.spring_layout(G, seed=42)  #to fix the cordinate of the nodes so that they dont 'jump around' for each iteration\n",
    "print(\"________Cell3 run_______\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b11c7e5-4151-4ca5-b2e7-d77221f4a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________cell4 ran________\n"
     ]
    }
   ],
   "source": [
    "#function for modularity matrix:\n",
    "\n",
    "def modularity_matrix(G):\n",
    "    n = G.number_of_nodes()\n",
    "    m = G.number_of_edges()\n",
    "\n",
    "    if m == 0:\n",
    "        return np.zeros((n,n))\n",
    "    \n",
    "    nodelist = sorted(G.nodes()) # gets sorted list of nodes in the grpah G\n",
    "\n",
    "    A = nx.to_numpy_array(G, nodelist)  # gets the adjacency matrix\n",
    "     \n",
    "    k = A.sum(axis=1) # to get sum along axis 1, that is the row of the adjaceny matrix; therefore gets the degree of each node\n",
    "    \n",
    "\n",
    "    expected_edges = np.outer(k, k) / (2 * m)\n",
    "    #outer product is a matrix where each entry is the product of an element from the first vector and an element from the second vector\n",
    "    #hence it gives the same required result like multiplying the vector and its transpose\n",
    "    \n",
    "    \n",
    "    B = A - expected_edges # modularity matrix is calculated here\n",
    "    \n",
    "    return B\n",
    "print(\"_________cell4 ran________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0e71984-e370-4af3-9186-60739936a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________cell5 ran___________\n"
     ]
    }
   ],
   "source": [
    "def find_communities(G):\n",
    "    \n",
    "# to perform iterative spectral bisection \n",
    "    \n",
    "    \n",
    "    B_global = modularity_matrix(G)\n",
    "    \n",
    "    all_nodes_list = sorted(G.nodes()) \n",
    "    node_indices = {node: i for i, node in enumerate(all_nodes_list)}  # maps each current node to its index(position) in the orignal global B\n",
    "    \n",
    "    queue = [all_nodes_list.copy()] #contains all the communities to be processed ; starts with having all the nodes\n",
    "    \n",
    "    final_communities = [] # list of all communities with negative eigen  value i.e. indivisible communities\n",
    "    \n",
    "   \n",
    "    partition_history = []\n",
    "    metric_history = []\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    \n",
    "    while queue:     # looped as long there the queue becomes empty\n",
    "        \n",
    "        \n",
    "        current_partition = final_communities.copy() + queue.copy() # The partition at this iteration is all final groups + all groups in the queue\n",
    "        partition_history.append(current_partition)\n",
    "        \n",
    "        iter_metrics = {\n",
    "            'degree': {},\n",
    "            'betweenness': {},\n",
    "            'closeness': {},\n",
    "            'clustering': {}\n",
    "        }\n",
    "        \n",
    "        for C in current_partition:\n",
    "            sub_G = G.subgraph(C)\n",
    "            n_sub = len(C)\n",
    "        #iterates through all the communities in the current partition to calculate the meterics\n",
    "            \n",
    "            if n_sub > 1:\n",
    "                #to exclude single node entries\n",
    "                deg = nx.degree_centrality(sub_G)  #count of how many edges (connections) a node has.\n",
    "                bet = nx.betweenness_centrality(sub_G)  #A measure of how often a node lies on the shortest path between other pairs of nodes in the network.; \n",
    "                                                        #broker/bridge\n",
    "                \n",
    "                if nx.is_connected(sub_G):    #closeness is only defined for connected graphs\n",
    "                    clo = nx.closeness_centrality(sub_G)  #A measure of how fast a node can reach every other node in the network. \n",
    "                                                          #It's based on the average of its shortest path distances to all other nodes.\n",
    "                else:\n",
    "                    clo = {node: 0.0 for node in C}  # else assign 0 if the subgraph is not connected\n",
    "                    \n",
    "                clu = nx.clustering(sub_G)         #estimate of how for a node, how well its neighboouring nodes are connected; checking for a closely knit group\n",
    "                \n",
    "                # Update the metrics dictionary\n",
    "                iter_metrics['degree'].update(deg)\n",
    "                iter_metrics['betweenness'].update(bet)\n",
    "                iter_metrics['closeness'].update(clo)\n",
    "                iter_metrics['clustering'].update(clu)\n",
    "                \n",
    "            elif n_sub == 1:\n",
    "                # Metrics for a single-node graph are 0\n",
    "                node = C[0]\n",
    "                iter_metrics['degree'][node] = 0.0\n",
    "                iter_metrics['betweenness'][node] = 0.0\n",
    "                iter_metrics['closeness'][node] = 0.0\n",
    "                iter_metrics['clustering'][node] = 0.0\n",
    "        \n",
    "        metric_history.append(iter_metrics)\n",
    "        \n",
    "    \n",
    "        if not queue:\n",
    "            break      # if the queue is empty , all possible communities are split , thus break out of the loop\n",
    "            \n",
    "    \n",
    "        nodes_to_split = queue.pop(0)     # Get first community in queue \n",
    "        \n",
    "        \n",
    "        if len(nodes_to_split) <= 1:  # if only one node is present, no possible splitting , thus its final\n",
    "            final_communities.append(nodes_to_split)\n",
    "            continue\n",
    "            \n",
    "\n",
    "        \n",
    "        indices = [node_indices[node] for node in nodes_to_split]    # Get the indices in B_global corresponding to our community\n",
    "        \n",
    "        B_restricted = B_global[np.ix_(indices, indices)]   #selects only the indices of our interest (from current partition) from the global modularity matrix\n",
    "                                                            #thus creates a sub matirx\n",
    "        \n",
    "        \n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(B_restricted)  # gets eigenvalue and eigenvector \n",
    "        \n",
    "        \n",
    "        lambda_1 = eigenvalues[-1]  # np.linalg.eigh() sorts eigenvalue in ascending order; so to get the largest eigenvalue , we need to take the last element\n",
    "        u_1 = eigenvectors[:, -1]   # to get the corresponding eigenvector\n",
    "        \n",
    "        # to stop iterations\n",
    "        if lambda_1 <= 1e-10:    # No positive eigenvalue, so no split improves modularity\n",
    "            final_communities.append(nodes_to_split)\n",
    "\n",
    "        \n",
    "        else:\n",
    "             #assigns each node to a group according to the value of the leading eigen value component corresponding to that node\n",
    "            C_plus = []   \n",
    "            C_minus = []\n",
    "            for i, node in enumerate(nodes_to_split):\n",
    "                \n",
    "                if u_1[i] > 0:        # Assign to communities based on sign of eigenvector \n",
    "                    C_plus.append(node)\n",
    "                else:                # Assign to communities based on sign of eigenvector\n",
    "                    C_minus.append(node)\n",
    "            \n",
    "            # Add the two new sub-communities back to the queue, for them to be examined again for next iteration\n",
    "            \n",
    "            if C_plus:\n",
    "                queue.append(C_plus)\n",
    "            if C_minus:\n",
    "                queue.append(C_minus)\n",
    "        \n",
    "        iteration += 1\n",
    "\n",
    "    return partition_history, metric_history\n",
    "\n",
    "print(\"___________cell5 ran___________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303c57f-8084-4d12-9f33-d5fe08d29fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7bd67-1b33-4fe6-b097-a7fc22479faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
